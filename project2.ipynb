{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Method(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readData(file_names):\n",
    "    #read data\n",
    "    corpus = \"\"\n",
    "    file_names = 'toy_data.txt'\n",
    "    f = open(file_names, 'r')\n",
    "    corpus = f.read()\n",
    "    #encode text string\n",
    "    corpus = corpus.replace('\\n',' ')\n",
    "    corpus = corpus.replace('\\t',' ')\n",
    "    corpus = corpus.replace('\"', ' ')\n",
    "    corpus = corpus.replace('\"', ' ')\n",
    "    for spaced in ['.','-',',','!','?','(','—',')']:\n",
    "        corpus = corpus.replace(spaced, ' {0} '.format(spaced))\n",
    "    corpus = corpus.replace('\\n',' ')\n",
    "    corpus = corpus.replace('\\t',' ')\n",
    "    corpus = corpus.replace('\"','')\n",
    "    corpus = corpus.replace('\"','')\n",
    "    for spaced in ['.','-',',','!','?','(','—',')',':']:\n",
    "        corpus = corpus.replace(spaced,' ')\n",
    "    dic_corpus = corpus.split()\n",
    "    #if use dictionary, it'll sort by itself\n",
    "    distinct_corpus = sorted(set(dic_corpus))\n",
    "    return dic_corpus,distinct_corpus\n",
    "\n",
    "def cleanup_data(sentence):\n",
    "    return sentence.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "def create_dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)\n",
    "\n",
    "#create probability dictionary \n",
    "def probability_dict(list_data):\n",
    "    probability_dict = {}\n",
    "    given_list_length = len(list_data)\n",
    "    for item in list_data:\n",
    "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
    "    for key, value in probability_dict.items():\n",
    "        probability_dict[key] = value / given_list_length\n",
    "    return probability_dict\n",
    "\n",
    "def Mat2Jason(matrix):\n",
    "    JMatrix = {}\n",
    "    for i,row in zip(list(range(np.size(matrix,axis=0))),matrix):\n",
    "        temp = {}\n",
    "        for j,val in zip(list(range(np.size(row,axis=0))),row):\n",
    "            temp[j] = val\n",
    "        JMatrix[i]=temp\n",
    "    return JMatrix\n",
    "  \n",
    "def TranMat(encodedCorpus):\n",
    "    nStates = len(encodedCorpus)\n",
    "    tranMat = np.zeros(shape=(nStates,nStates))\n",
    "    for i in range(0,nStates):\n",
    "        fndEl = list(np.where(encodedCorpus==i)[0])\n",
    "        for el in fndEl:\n",
    "              if(el +1 != len(encodedCorpus)):\n",
    "                tranMat[i,encodedCorpus[el+1]] += 1/len(fndEl)\n",
    "    \n",
    "    ''' Laplace Smoothing to normalize the matrix '''\n",
    "#     tranMat[tranMat!=0] = TranMat[TranMat!=0] + (1/nStates)\n",
    "#     TranMat[TranMat==0] = 1/nStates\n",
    "    return tranMat\n",
    "\n",
    "def emisMat():\n",
    "    pass\n",
    "    \n",
    "def ForwardAlg(observations, initialprob, trans, emis, numstates, observation_indices):\n",
    "    alpha = np.zeros((numstates, len(observations)))\n",
    "      # initialization\n",
    "    obs_index = observation_indices[observations[0]]\n",
    "    for s in range(numstates):\n",
    "          forwardmatrix[s,0] = initialprob[s]*emis[s,obs_index]\n",
    "\n",
    "      # recursion\n",
    "    for t in range(1, len(observations)):\n",
    "        obs_index = observation_indices[observations[t]]\n",
    "        for s in range(numstates):\n",
    "            forwardmatrix[s,t] = emis[s,obs_index]*sum([forwardmatrix[s2,t-1]*trans[s2,s] for s2 in range(numstates)])\n",
    "    return forwardmatrix\n",
    "\n",
    "\n",
    "def BackwardAlg(observations, trans, emis, numstates, observation_indices):\n",
    "    backwardmatrix = numpy.zeros((numstates, len(observations)))\n",
    "      # initialization\n",
    "    for s in range(numstates):\n",
    "        backwardmatrix[ s, len(observations) - 1 ] = 1.0\n",
    "\n",
    "      # recursion\n",
    "    for t in range(len(observations) - 2, -1, -1):\n",
    "        obs_index = observation_indices[ observations[t+1]]\n",
    "        for s in range(numstates):\n",
    "            backwardmatrix[s,t] = sum([trans[s,s2]*emis[s2,obs_index]*backwardmatrix[s2,t+1] for s2 in range(numstates)])\n",
    "\n",
    "    return backwardmatrix\n",
    "\n",
    "\n",
    "#List to hold the initial states and transition states\n",
    "initial_word = {}\n",
    "second_word = {}\n",
    "transitions = {}\n",
    "for line in open('alllines.txt'):\n",
    "    tokens = cleanup_data(line.rstrip().lower()).split()\n",
    "    tokens_length = len(tokens)\n",
    "    for i in range(tokens_length):\n",
    "        token = tokens[i]\n",
    "        if i == 0:\n",
    "            initial_word[token] = initial_word.get(token, 0) + 1\n",
    "        else:\n",
    "            prev_token = tokens[i - 1]\n",
    "            if i == tokens_length - 1:\n",
    "                create_dict(transitions, (prev_token, token), 'END')\n",
    "            if i == 1:\n",
    "                create_dict(second_word, prev_token, token)\n",
    "            else:\n",
    "                prev_prev_token = tokens[i - 2]\n",
    "                create_dict(transitions, (prev_prev_token, prev_token), token)\n",
    "\n",
    "# Normalize the distributions\n",
    "initial_word_total = sum(initial_word.values())\n",
    "for key, value in initial_word.items():\n",
    "    initial_word[key] = value / initial_word_total\n",
    "\n",
    "for prev_word, next_word_list in second_word.items():\n",
    "    second_word[prev_word] = probability_dict(next_word_list)\n",
    "\n",
    "for word_pair, next_word_list in transitions.items():\n",
    "    transitions[word_pair] = probability_dict(next_word_list)\n",
    "# Init_prob = probability_dict(dic_corpus)\n",
    "# #Init_prob\n",
    "# observations = distinct_corpus\n",
    "# #create dict for observation w/ index\n",
    "# observation_indices = dict(zip(observations, range(len(observations))))\n",
    "# #trans = TranMat(dic_corpus)\n",
    "# numstates = len(observations)\n",
    "# tranMat = TranMat(observations)\n",
    "# emisMat = tranMat.transpose(1,0)\n",
    "# obs_index = observation_indices[observations[1]]\n",
    "# tranMat   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATIONS:\n",
      "[3, 2]\n",
      "\n",
      "\n",
      "Random initialization:\n",
      "INITIALPROB\n",
      "[0.037526   0.00944889 0.03466626 0.02945669 0.01022185 0.02625524\n",
      " 0.01549539 0.02834354 0.01309296 0.00806054 0.01947283 0.02131691\n",
      " 0.03758229 0.01921765 0.02403569 0.02831827 0.02998779 0.01355308\n",
      " 0.0056531  0.03203963 0.00170184 0.00663279 0.02973708 0.02456977\n",
      " 0.0074998  0.03775232 0.026192   0.03161647 0.03632377 0.01545876\n",
      " 0.02861992 0.01279833 0.02792261 0.01624828 0.03826539 0.01493279\n",
      " 0.00141517 0.03840007 0.00735803 0.02096796 0.00752855 0.00058176\n",
      " 0.03436286 0.02774676 0.02790723 0.03371512]\n",
      "\n",
      "\n",
      "EMIS\n",
      "[[0.02604598 0.03655737 0.01536641 ... 0.00367525 0.03430004 0.02123023]\n",
      " [0.04260959 0.02503871 0.02586685 ... 0.0042876  0.00436766 0.00777747]\n",
      " [0.01117842 0.0246133  0.02436358 ... 0.02106072 0.01078962 0.00467217]\n",
      " ...\n",
      " [0.02424153 0.00149627 0.00901634 ... 0.03954017 0.00480719 0.01583308]\n",
      " [0.03971759 0.01090224 0.00508391 ... 0.0219325  0.04271273 0.01073496]\n",
      " [0.0218303  0.0356976  0.01784871 ... 0.03888104 0.02218272 0.00937485]]\n",
      "\n",
      "\n",
      "TRANS\n",
      "[[0.00229336 0.02160009 0.01336771 ... 0.00977304 0.02077016 0.04187366]\n",
      " [0.01506708 0.00206494 0.0235311  ... 0.00339793 0.00782329 0.03339232]\n",
      " [0.03823768 0.04248172 0.00675829 ... 0.00024184 0.02627435 0.02917941]\n",
      " ...\n",
      " [0.03543709 0.03091715 0.00097265 ... 0.03450568 0.00616233 0.01752522]\n",
      " [0.03776166 0.02663175 0.00387613 ... 0.00428106 0.01226854 0.00464092]\n",
      " [0.01904329 0.02034141 0.03335729 ... 0.03661546 0.03844561 0.02388718]]\n",
      "\n",
      "\n",
      "Re-computed:\n",
      "INITIALPROB\n",
      "[3.67845241e-03 5.01341206e-04 3.99212010e-04 5.54036428e-04\n",
      " 9.21248050e-06 3.14605105e-02 3.54704422e-02 1.99906514e-07\n",
      " 1.72229377e-02 8.04503277e-09 1.16929969e-02 6.66479438e-02\n",
      " 1.31884282e-01 8.04633251e-06 5.95357793e-02 8.93175293e-02\n",
      " 6.22981997e-16 1.95516112e-09 6.64922744e-19 1.29322827e-01\n",
      " 2.39166367e-22 1.16656231e-02 7.24245932e-15 1.45061612e-19\n",
      " 1.55614065e-09 3.33499933e-02 2.70270546e-04 6.73354719e-03\n",
      " 1.05309220e-10 1.07411440e-03 1.59670896e-02 1.67968886e-03\n",
      " 2.05859223e-02 2.30702680e-03 9.86024447e-02 2.88932587e-04\n",
      " 5.25656272e-04 1.62904826e-02 1.26981917e-09 2.20252345e-05\n",
      " 6.84300724e-04 5.09838751e-40 1.92938393e-03 8.75180933e-02\n",
      " 1.22382949e-01 4.16693154e-04]\n",
      "\n",
      "\n",
      "EMIS\n",
      "[[2.03926243e-01 7.96073757e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.40749214e-02 9.65925079e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.92238648e-02 9.60776135e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 1.78023256e-22 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.24761416e-11 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.43358019e-02 9.85664198e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "\n",
      "TRANS\n",
      "[[1.37020473e-03 1.78258172e-02 1.10718172e-02 ... 1.00681463e-23\n",
      "  7.34449199e-12 5.68476667e-02]\n",
      " [6.36775485e-03 1.20544224e-03 1.37863432e-02 ... 2.47616655e-24\n",
      "  1.95684542e-12 3.20673699e-02]\n",
      " [1.96128840e-02 3.00977229e-02 4.80547477e-03 ... 2.13883633e-25\n",
      "  7.97611987e-12 3.40083744e-02]\n",
      " ...\n",
      " [1.73885179e-02 2.09549018e-02 6.61621466e-04 ... 2.91946278e-23\n",
      "  1.78961374e-12 1.95401252e-02]\n",
      " [1.74522194e-02 1.70012542e-02 2.48340632e-03 ... 3.41160728e-24\n",
      "  3.35584735e-12 4.87374641e-03]\n",
      " [9.97652998e-03 1.47197418e-02 2.42257873e-02 ... 3.30757625e-23\n",
      "  1.19204878e-11 2.84355574e-02]]\n",
      "\n",
      "\n",
      "GAMMA(1)\n",
      "[0.00367845 0.0143597 ]\n",
      "\n",
      "\n",
      "GAMMA(2)\n",
      "[0.00050134 0.01421157]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# expectation step:\n",
    "# re-estimate xi_t(i, j) and gamma_t(j)\n",
    "# returns two things:\n",
    "# - gamma is a (N, T) numpy matrix\n",
    "# - xi is a list of T numpy matrices of size (N, N)\n",
    "def expectation(observations, trans, emis, numstates, observation_indices, forward, backward):\n",
    "    # denominator: P(O | HMM)\n",
    "    p_o_given_hmm = sum([forward[s_i, len(observations) -1] for s_i in range(numstates) ])\n",
    "   \n",
    "    # computing xi\n",
    "    xi = [ ]\n",
    "    for t in range(len(observations) - 1):\n",
    "        obs_index = observation_indices[observations[t+1]]\n",
    "       \n",
    "        xi_t = np.zeros((numstates, numstates))\n",
    "       \n",
    "        for s_i in range(numstates):\n",
    "            for s_j in range(numstates):\n",
    "                xi_t[ s_i, s_j] = (forward[s_i, t] * trans[s_i, s_j] * emis[s_j, obs_index] * backward[s_j, t+1]) / p_o_given_hmm\n",
    "        xi.append(xi_t)\n",
    "\n",
    "    # computing gamma\n",
    "    gamma = np.zeros((numstates + 2, len(observations)))\n",
    "    for t in range(len(observations) - 1):\n",
    "        for s_i in range(numstates):\n",
    "            gamma[s_i, t] = sum([ xi[t][s_i, s_j] for s_j in range(numstates) ])\n",
    "\n",
    "    for s_j in range(numstates):\n",
    "        gamma[s_j, len(observations) - 1] = sum( [ xi[t][s_i, s_j] for s_i in range(numstates) ] )\n",
    "           \n",
    "    return (gamma, xi)\n",
    "\n",
    "###\n",
    "# maximization step:\n",
    "# re-estimate trans, emis based on gamma, xi\n",
    "# returns:\n",
    "# - initialprob\n",
    "# - trans\n",
    "# - emis\n",
    "def maximization(observations, gamma, xi, numstates, observation_indices, vocabsize):\n",
    "    # re-estimate initial probabilities\n",
    "    initialprob = np.array([gamma[s_i, 0] for s_i in range(numstates)])\n",
    "   \n",
    "    # re-estimate emission probabilities\n",
    "    emis = np.zeros((numstates, vocabsize))\n",
    "\n",
    "    for s in range(numstates):\n",
    "        denominator = sum( [gamma[s, t] for t in range(len(observations))])\n",
    "        for vocab_item, obs_index in observation_indices.items():\n",
    "            emis[s, obs_index] = sum( [gamma[s, t] for t in range(len(observations)) if observations[t] == vocab_item] )/denominator\n",
    "\n",
    "    # re-estimate transition probabilities\n",
    "    trans = np.zeros((numstates, numstates))\n",
    "\n",
    "    for s_i in range(numstates):\n",
    "        denominator = sum( [gamma[s_i, t] for t in range(len(observations) - 1) ])\n",
    "       \n",
    "        for s_j in range(numstates):\n",
    "            trans[s_i, s_j] = sum( [ xi[t][s_i, s_j] for t in range(len(observations) - 1) ] )/denominator\n",
    "\n",
    "\n",
    "    return (initialprob, trans, emis)\n",
    "\n",
    "# forward function: returns numpy matrix of size (N, T)\n",
    "def forwardprobs(observations, initialprob, trans, emis, numstates, observation_indices):\n",
    "    forwardmatrix = np.zeros((numstates, len(observations)))\n",
    "\n",
    "    # initialization\n",
    "    obs_index = observation_indices[ observations[0]]\n",
    "    for s in range(numstates):\n",
    "        forwardmatrix[ s, 0 ] = initialprob[s] * emis[ s, obs_index]\n",
    "\n",
    "    # recursion step\n",
    "    for t in range(1, len(observations)):\n",
    "        obs_index = observation_indices[ observations[t]]\n",
    "        for s in range(numstates):\n",
    "            forwardmatrix[s, t] = emis[s, obs_index] * sum([forwardmatrix[s2, t-1] * trans[s2, s] \\\n",
    "                                       for s2 in range(numstates)])\n",
    "    return forwardmatrix\n",
    "\n",
    "# beta_t(j) = P(o_{t+1}, ..., o_T | qt = j, HMM)\n",
    "# backward function: returns numpy matrix of size (N, T)\n",
    "def backwardprobs(observations, trans, emis, numstates, observation_indices):\n",
    "    backwardmatrix = np.zeros((numstates, len(observations)))\n",
    "\n",
    "    # initialization\n",
    "    for s in range(numstates):\n",
    "        backwardmatrix[ s, len(observations) - 1 ] = 1.0\n",
    "\n",
    "    # recursion\n",
    "    for t in range(len(observations) - 2, -1, -1):\n",
    "        obs_index = observation_indices[ observations[t+1]]\n",
    "        for s in range(numstates):\n",
    "            backwardmatrix[s, t] = sum([ trans[s, s2] * emis[s2, obs_index] * backwardmatrix[s2, t+1] \\\n",
    "                                         for s2 in range(numstates) ])\n",
    "\n",
    "    return backwardmatrix\n",
    "# HMM initialization\n",
    "# initialize initial probs\n",
    "obs_indices = dict(zip(observations, range(len(observations))))\n",
    "nStates = len(encodedCorpus)\n",
    "vocabsize = len(encodedCorpus)\n",
    "unnormalized = np.random.rand(nStates)\n",
    "initialprob = unnormalized / sum(unnormalized)\n",
    "numiter = 5\n",
    "# initialize emission probs\n",
    "emis = np.zeros((nStates, vocabsize))\n",
    "for s in range(nStates):\n",
    "    unnormalized = np.random.rand(vocabsize)\n",
    "    emis[s] = unnormalized / sum(unnormalized)\n",
    "\n",
    "# initialize transition probs\n",
    "trans = np.zeros((nStates, nStates))\n",
    "for s in range(nStates):\n",
    "    unnormalized = np.random.rand(nStates)\n",
    "    trans[s] = unnormalized / sum(unnormalized)\n",
    "\n",
    "print(\"OBSERVATIONS:\")\n",
    "print(observations)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Random initialization:\")\n",
    "print(\"INITIALPROB\")\n",
    "print(initialprob)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"EMIS\")\n",
    "print(emis)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"TRANS\")\n",
    "print(trans)\n",
    "print(\"\\n\")\n",
    "for iteration in range(numiter):\n",
    "\n",
    "    forward = forwardprobs(observations, initialprob, trans, emis, nStates, obs_indices)\n",
    "    backward = backwardprobs(observations, trans, emis, nStates, obs_indices)\n",
    "\n",
    "    gamma, xi = expectation(observations, trans, emis, nStates, obs_indices, forward, backward)\n",
    "\n",
    "    initialprob, trans, emis = maximization(observations, gamma, xi, nStates, obs_indices, vocabsize)\n",
    "\n",
    "print(\"Re-computed:\")\n",
    "print(\"INITIALPROB\")\n",
    "print(initialprob)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"EMIS\")\n",
    "print(emis)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"TRANS\")\n",
    "print(trans)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"GAMMA(1)\")\n",
    "print(gamma[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"GAMMA(2)\")\n",
    "print(gamma[1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ViterbiAlg(trans, emis, observations):\n",
    "    num_obs = len(observations)\n",
    "    num_states = tranMat.shape[0]\n",
    "    log_probs = np.zeros(num_states)\n",
    "    paths = np.zeros( (num_states, num_obs+1 ))\n",
    "    paths[:, 0] = np.arange(num_states)    \n",
    "    for obs_ind, obs_val in enumerate(observations):\n",
    "        for state_ind in range(num_states):\n",
    "            val = 0\n",
    "            if obs_val< np.size(EmissMat,1):\n",
    "                val = np.log(EmissMat[state_ind, obs_val])\n",
    "            temp_probs = log_probs + \\\n",
    "                          val + \\\n",
    "                         np.log(tranMat[:, state_ind])\n",
    "            best_temp_ind = np.argmax(temp_probs)\n",
    "            paths[state_ind,:] = paths[best_temp_ind,:]\n",
    "            paths[state_ind,(obs_ind+1)] = state_ind\n",
    "            log_probs[state_ind] = temp_probs[best_temp_ind]\n",
    "    best_path_ind = np.argmax(log_probs)\n",
    "    \n",
    "    return (paths[best_path_ind], log_probs[best_path_ind])\n",
    "\n",
    "def text_prediction(text):\n",
    "        text = cleanup_data(text.lower()).split()\n",
    "        # Initial word\n",
    "        word0 = text[0]\n",
    "        # Second word\n",
    "        if len(text) == 1:\n",
    "            word1 = sample_word(second_word[word0])\n",
    "            text.append(word1)\n",
    "        else:\n",
    "            word1 = text[1]\n",
    "        # Subsequent words untill END\n",
    "        while True:\n",
    "            word2 = max(transitions[(word0, word1)], key=transitions[(word0, word1)].get)\n",
    "            if word2 == 'END':\n",
    "                break\n",
    "            text.append(word2)\n",
    "            word0 = word1\n",
    "            word1 = word2\n",
    "        print(' '.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Generating new text from the text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dictionary):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for key, value in dictionary.items():\n",
    "        cumulative += value\n",
    "        if p0 < cumulative:\n",
    "            return key\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sample text\n",
    "def generate_text(number_of_sentences):\n",
    "    for i in range(number_of_sentences):\n",
    "        sentence = []\n",
    "        # Initial word\n",
    "        word0 = sample_word(initial_word)\n",
    "        sentence.append(word0)\n",
    "        # Second word\n",
    "        word1 = sample_word(second_word[word0])\n",
    "        sentence.append(word1)\n",
    "        # Subsequent words untill END\n",
    "        while True:\n",
    "            word2 = sample_word(transitions[(word0, word1)])\n",
    "            if word2 == 'END':\n",
    "                break\n",
    "            sentence.append(word2)\n",
    "            word0 = word1\n",
    "            word1 = word2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he shall not save him sir within himself\n",
      "my thoughts and troubles\n",
      "come sir i will confess what i speak too\n",
      "and their army\n",
      "as priam was for not being at your hand and smiles on the commonwealth and made her neighbours believe she\n"
     ]
    }
   ],
   "source": [
    "dic_corpus,distinct_corpus = readData('alllines.txt')\n",
    "generate_text(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Perform text prediction on sequantial words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my marvel and my good lord\n"
     ]
    }
   ],
   "source": [
    "text_prediction(\"my marvel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
